{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFY DATA\n",
    "\n",
    "Classify data for machine learning algorithm training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Reading files\n",
    "import h5py\n",
    "import toml\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "#sns.set_context('paper')\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import subprocess\n",
    "from random import choice\n",
    "import time as pytime\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Suppress NaturalNameWarning raised by HDFStore\n",
    "import warnings\n",
    "import tables\n",
    "warnings.filterwarnings('ignore', category=tables.NaturalNameWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Create folders `ris` and `ris/plots` and initialize classification parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'ris' folder\n",
    "if not os.path.exists('ris'):\n",
    "    os.makedirs('ris')\n",
    "# Create 'plot' folder\n",
    "if not os.path.exists('ris/plots'):\n",
    "    os.makedirs('ris/plots')\n",
    "    \n",
    "# Parameters\n",
    "INTERVAL_LENGTH = 100\n",
    "OPERATING_DAY_LIST = ['091', '092', '093', '094', '095', '096', '097', '098', '099', '100', '101', '102', '103', '104', '105']\n",
    "DETECTOR_LIST = ['143-5', '143-6', '143-7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "### Define the classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def classify():\n",
    "    \n",
    "    # Load parameters and status from a toml file\n",
    "    STATUS = toml.load('status.toml')\n",
    "    \n",
    "    print('ACTUAL STATUS:\\n', STATUS)\n",
    "\n",
    "    # Choose random operating day and detector\n",
    "    OD = choice(OPERATING_DAY_LIST)\n",
    "    DET = choice(DETECTOR_LIST)\n",
    "    CHOICE = '/' + OD + '/' + DET\n",
    "\n",
    "    if len(data[CHOICE].index.values) % 2 == 0:\n",
    "        limit_interval = 1.1 * np.median(data[CHOICE].index.values[1::2] - data[CHOICE].index.values[::2])\n",
    "    else:\n",
    "        limit_interval = 1.1 * np.median(data[CHOICE].index.values[1::2] - data[CHOICE].index.values[:-1:2])\n",
    "\n",
    "    # Choose a random starting point. If the difference in time is too big, it means I'm taking the data over a 'hole'.\n",
    "    print('\\nEXTRACTING DATA FROM: OPERATING DAY ' + OD + ' - DETECTOR ' + DET)\n",
    "    print('Searching interval...')\n",
    "    i = 1\n",
    "    print('Attempt:', i, '\\r', end='')\n",
    "    begin = int((len(data[CHOICE].index.values) - 200) * np.random.random())\n",
    "    end = begin + INTERVAL_LENGTH\n",
    "    while((data[CHOICE].index.values[end] - data[CHOICE].index.values[begin]) > INTERVAL_LENGTH * limit_interval):\n",
    "        i += 1\n",
    "        print('Attempt:', i, '\\r', end='')\n",
    "        begin = int((len(data[CHOICE].index.values) - 200) * np.random.random())\n",
    "        end = begin + INTERVAL_LENGTH\n",
    "    print('\\n')\n",
    "\n",
    "    # Plot\n",
    "    plt.plot(data[CHOICE].iloc[begin:end], marker='.', linestyle='dashed')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Classify\n",
    "    print('\\nStep:', STATUS['N'])\n",
    "    print('Choice: [ yes (y) | no (n) | multi (m) | beautiful glitch (yb) | beautiful no-glitch (nb) | beautiful multi (mb) ]')\n",
    "    print('Type \"exit\" to interrupt.')\n",
    "    answer = input('Do you see a glitch?')\n",
    "    \n",
    "    # Create DataFrame\n",
    "    if answer in ['y', 'yb', 'n', 'nb', 'm', 'mb']:\n",
    "        df = pd.DataFrame({'data': data[CHOICE]['data_cleaned'].iloc[begin:end]}, index=data[CHOICE].iloc[begin:end].index.values)\n",
    "        df.index.name = 'time'\n",
    "\n",
    "    # GLITCH\n",
    "    # Normal\n",
    "    if answer == 'y':\n",
    "        print('Glitch detected.')\n",
    "        # Update status\n",
    "        STATUS['N_GLITCH'] += 1\n",
    "        STATUS['N'] += 1\n",
    "        # Save data\n",
    "        dataname = 'GLITCH/' + str(STATUS['N_GLITCH'])\n",
    "        with pd.HDFStore('ris/OUT-classified.h5') as out_file:\n",
    "            out_file.put(dataname, df)\n",
    "        with h5py.File('ris/OUT-classified.h5') as out_file:\n",
    "            out_file[dataname].attrs['TITLE'] = np.string_('From: ' + CHOICE)\n",
    "            out_file[dataname].attrs['VERSION'] = np.string_('Date: ' + pytime.asctime() + ' | Script name: classification.ipynb | Script commit ID: ' + subprocess.run(['git', 'log', '-1', '--format=%H', 'classification.ipynb'], stdout=subprocess.PIPE).stdout.decode('ASCII').rstrip())   \n",
    "    # Beautiful\n",
    "    elif answer == 'yb':\n",
    "        print('Glitch detected; saved.')\n",
    "        # Update status\n",
    "        STATUS['N_GLITCH'] += 1\n",
    "        STATUS['N'] += 1\n",
    "        # Save data\n",
    "        dataname = 'GLITCH/' + str(STATUS['N_GLITCH'])\n",
    "        with pd.HDFStore('ris/OUT-classified.h5') as out_file:\n",
    "            out_file.put(dataname, df)\n",
    "        with h5py.File('ris/OUT-classified.h5') as out_file:\n",
    "            out_file[dataname].attrs['TITLE'] = np.string_('From: ' + CHOICE)\n",
    "            out_file[dataname].attrs['VERSION'] = np.string_('Date: ' + pytime.asctime() + ' | Script name: classification.ipynb | Script commit ID: ' + subprocess.run(['git', 'log', '-1', '--format=%H', 'classification.ipynb'], stdout=subprocess.PIPE).stdout.decode('ASCII').rstrip())   \n",
    "        # Save plot\n",
    "        plt.plot(data[CHOICE].iloc[begin:end], marker='.', linestyle='dashed')\n",
    "        plt.title('Glitch ' + str(STATUS['N_GLITCH']))\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Signal [T_cmb V / W]')\n",
    "        plt.savefig('ris/plots/glitch-' + str(STATUS['N_GLITCH']) + '.png', dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    # NO GLITCH\n",
    "    # Normal\n",
    "    elif answer == 'n':\n",
    "        print('No glitch detected.')\n",
    "        # Update status\n",
    "        STATUS['N_NO_GLITCH'] += 1\n",
    "        STATUS['N'] += 1\n",
    "        # Save data\n",
    "        dataname = 'NO_GLITCH/' + str(STATUS['N_NO_GLITCH'])\n",
    "        with pd.HDFStore('ris/OUT-classified.h5') as out_file:\n",
    "            out_file.put(dataname, df)\n",
    "        with h5py.File('ris/OUT-classified.h5') as out_file:\n",
    "            out_file[dataname].attrs['TITLE'] = np.string_('From: ' + CHOICE)\n",
    "            out_file[dataname].attrs['VERSION'] = np.string_('Date: ' + pytime.asctime() + ' | Script name: classification.ipynb | Script commit ID: ' + subprocess.run(['git', 'log', '-1', '--format=%H', 'classification.ipynb'], stdout=subprocess.PIPE).stdout.decode('ASCII').rstrip())   \n",
    "    # Beautiful\n",
    "    elif answer == 'nb':\n",
    "        print('No glitch detected; saved.')\n",
    "        # Update status\n",
    "        STATUS['N_NO_GLITCH'] += 1\n",
    "        STATUS['N'] += 1\n",
    "        # Save data\n",
    "        dataname = 'NO_GLITCH/' + str(STATUS['N_NO_GLITCH'])\n",
    "        with pd.HDFStore('ris/OUT-classified.h5') as out_file:\n",
    "            out_file.put(dataname, df)\n",
    "        with h5py.File('ris/OUT-classified.h5') as out_file:\n",
    "            out_file[dataname].attrs['TITLE'] = np.string_('From: ' + CHOICE)\n",
    "            out_file[dataname].attrs['VERSION'] = np.string_('Date: ' + pytime.asctime() + ' | Script name: classification.ipynb | Script commit ID: ' + subprocess.run(['git', 'log', '-1', '--format=%H', 'classification.ipynb'], stdout=subprocess.PIPE).stdout.decode('ASCII').rstrip())   \n",
    "        # Save plot\n",
    "        plt.plot(data[CHOICE].iloc[begin:end], marker='.', linestyle='dashed')\n",
    "        plt.title('No glitch ' + str(STATUS['N_NO_GLITCH']))\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Signal [T_cmb V / W]')\n",
    "        plt.savefig('ris/plots/no_glitch-' + str(STATUS['N_NO_GLITCH']) + '.png', dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    # MULTI GLITCH\n",
    "    # Normal\n",
    "    elif answer == 'm':\n",
    "        print('Multi glitch detected.')\n",
    "        # Update status\n",
    "        STATUS['N_MULTI'] += 1\n",
    "        STATUS['N'] += 1\n",
    "        # Save data\n",
    "        dataname = 'MULTI_GLITCH/' + str(STATUS['N_MULTI'])\n",
    "        with pd.HDFStore('ris/OUT-classified.h5') as out_file:\n",
    "            out_file.put(dataname, df)\n",
    "        with h5py.File('ris/OUT-classified.h5') as out_file:\n",
    "            out_file[dataname].attrs['TITLE'] = np.string_('From: ' + CHOICE)\n",
    "            out_file[dataname].attrs['VERSION'] = np.string_('Date: ' + pytime.asctime() + ' | Script name: classification.ipynb | Script commit ID: ' + subprocess.run(['git', 'log', '-1', '--format=%H', 'classification.ipynb'], stdout=subprocess.PIPE).stdout.decode('ASCII').rstrip())   \n",
    "    # Beautiful\n",
    "    elif answer == 'mb':\n",
    "        print('Multi glitch detected; saved.')\n",
    "        # Update status\n",
    "        STATUS['N_MULTI'] += 1\n",
    "        STATUS['N'] += 1\n",
    "        # Save data\n",
    "        dataname = 'MULTI_GLITCH/' + str(STATUS['N_MULTI'])\n",
    "        with pd.HDFStore('ris/OUT-classified.h5') as out_file:\n",
    "            out_file.put(dataname, df)\n",
    "        with h5py.File('ris/OUT-classified.h5') as out_file:\n",
    "            out_file[dataname].attrs['TITLE'] = np.string_('From: ' + CHOICE)\n",
    "            out_file[dataname].attrs['VERSION'] = np.string_('Date: ' + pytime.asctime() + ' | Script name: classification.ipynb | Script commit ID: ' + subprocess.run(['git', 'log', '-1', '--format=%H', 'classification.ipynb'], stdout=subprocess.PIPE).stdout.decode('ASCII').rstrip())   \n",
    "        # Save plot\n",
    "        plt.plot(data[CHOICE].iloc[begin:end], marker='.', linestyle='dashed')\n",
    "        plt.title('Multi glitch ' + str(STATUS['N_MULTI']))\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.ylabel('Signal [T_cmb V / W]')\n",
    "        plt.savefig('ris/plots/multi_glitch-' + str(STATUS['N_MULTI']) + '.png', dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    elif answer == 'exit':\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        print('Unable to classify.')\n",
    "\n",
    "    # Save parameters\n",
    "    with open('status.toml', mode='w') as toml_status_file:\n",
    "        toml.dump(STATUS, toml_status_file)\n",
    "    \n",
    "    # Clear output\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify\n",
    "\n",
    "Now run this function how many times you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open cleaned data file\n",
    "data = pd.HDFStore('../cleaning/ris/OUT-cleaned.h5', mode='r')\n",
    "\n",
    "# Classify\n",
    "while classify() != 'exit':\n",
    "    pass\n",
    "\n",
    "# Close data file\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility\n",
    "\n",
    "### Print classified data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "with pd.HDFStore('ris/OUT-classified.h5') as out_file:\n",
    "    print(out_file.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find `143-7` data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "with pd.HDFStore('ris/OUT-classified.h5') as out_file:\n",
    "    k = out_file.keys()\n",
    "with h5py.File('ris/OUT-classified.h5') as out_file:\n",
    "    n = 0\n",
    "    for df_name in k:\n",
    "        if b'143-7' in out_file[df_name].attrs['TITLE']:\n",
    "            n += 1\n",
    "print(n, toml.load('status.toml')[\"N\"], n/toml.load('status.toml')[\"N\"])r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot graphs\n",
    "Plot classified data and check if there are errors or no."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# G  : 59\n",
    "# NG : 110\n",
    "# MG : 25\n",
    "\n",
    "with pd.HDFStore('ris/OUT-classified.h5', mode='r') as f:\n",
    "    \n",
    "    # Insert group of interest\n",
    "    GROUP = '/MULTI_GLITCH/'\n",
    "    # List group keys\n",
    "    GROUP_KEYS = list(*f.walk(GROUP))[2]\n",
    "    print(GROUP_KEYS)\n",
    "    GROUP_KEYS = np.array(list(map(int, GROUP_KEYS)))\n",
    "    GROUP_KEYS.sort()\n",
    "    \n",
    "    for obj in GROUP_KEYS:\n",
    "        obj = str(obj)\n",
    "        # Plot\n",
    "        plt.plot(f[GROUP + obj]['time'], f[GROUP + obj]['data'], marker='.', linestyle='dashed')\n",
    "        plt.title(GROUP + obj)\n",
    "        plt.show()\n",
    "        pytime.sleep(0.2)\n",
    "        # Clear output\n",
    "        clear_output(wait=True)\n",
    "\n",
    "print('FINISHED.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset the classification\n",
    "Reset the classification by removing `OUT-classified.h5` file and `plot` folder. **REMEMBER TO MOVE INTERESTING PLOTS INTO THE `ris` FOLDER!**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "if False:\n",
    "    answer = input('Are you sure?')\n",
    "    if answer == 'yes':\n",
    "        answer = input('This will delete 'plots' folder and 'OUT-classified.h5' file!')\n",
    "        if answer == 'yes':\n",
    "            # Remove classified data\n",
    "            import os\n",
    "            import shutil\n",
    "            if os.path.exists('ris/plots'):\n",
    "                shutil.rmtree('ris/plots')\n",
    "            if os.path.exists('ris/OUT-classified.h5'):\n",
    "                os.remove('ris/OUT-classified.h5')\n",
    "            # Reset status\n",
    "            N = 0\n",
    "            N_GLITCH = 0\n",
    "            N_MULTI = 0\n",
    "            N_NO_GLITCH = 0\n",
    "            toml_status_dict = {'N': N, 'N_GLITCH': N_GLITCH, 'N_MULTI': N_MULTI, 'N_NO_GLITCH': N_NO_GLITCH}\n",
    "            with open('status.toml', mode='w') as toml_status_file:\n",
    "                import toml\n",
    "                toml.dump(toml_status_dict, toml_status_file)\n",
    "            print('DONE.')\n",
    "            # Restart kernel\n",
    "            import time as pytime\n",
    "            pytime.sleep(3)\n",
    "            os._exit(0)\n",
    "        else:\n",
    "            print('ABORTED.')\n",
    "    else:\n",
    "        print('ABORTED.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
