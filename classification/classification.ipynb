{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFY DATA\n",
    "\n",
    "Classify data for machine learning algorithm training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Reading files\n",
    "import h5py\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "#sns.set_context(\"paper\")\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import toml\n",
    "from random import choice\n",
    "import time as pytime\n",
    "import subprocess\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Suppress NaturalNameWarning raised by HDFStore\n",
    "import warnings\n",
    "import tables\n",
    "warnings.filterwarnings(\"ignore\", category=tables.NaturalNameWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## toml generators\n",
    "### Parameter generator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#I set number of points displayed per random graph\n",
    "INTERVAL_LENGTH = 100\n",
    "\n",
    "# Operating day list\n",
    "OPERATING_DAY_LIST = []\n",
    "for OPERATING_DAY in range(91,106):\n",
    "    if OPERATING_DAY < 100:\n",
    "        OPERATING_DAY_LIST.append(\"0\" + str(OPERATING_DAY))\n",
    "    else:\n",
    "        OPERATING_DAY_LIST.append(str(OPERATING_DAY))\n",
    "        \n",
    "# Detector list\n",
    "DETECTOR_LIST = [\"143-5\", \"143-6\", \"143-7\"]\n",
    "\n",
    "# Create dictionary\n",
    "toml_parameters_dict = {\"INTERVAL_LENGTH\": INTERVAL_LENGTH, \"OPERATING_DAY_LIST\": OPERATING_DAY_LIST, \"DETECTOR_LIST\": DETECTOR_LIST}\n",
    "# Save toml file\n",
    "with open(\"parameters.toml\", mode=\"w\") as toml_parameters_file:\n",
    "    toml.dump(toml_parameters_dict, toml_parameters_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status generator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "N = 0\n",
    "N_GLITCH = 0\n",
    "N_LONG = 0\n",
    "N_NO_GLITCH = 0\n",
    "\n",
    "# Create dictionary\n",
    "toml_status_dict = {\"N\": N, \"N_GLITCH\": N_GLITCH, \"N_LONG\": N_LONG, \"N_NO_GLITCH\": N_NO_GLITCH}\n",
    "# Save toml file\n",
    "with open(\"status.toml\", mode=\"w\") as toml_status_file:\n",
    "    toml.dump(toml_status_dict, toml_status_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Create folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'ris' folder\n",
    "if not os.path.exists(\"ris\"):\n",
    "    os.makedirs(\"ris\")\n",
    "# Create 'plot' folder\n",
    "if not os.path.exists(\"ris/plots\"):\n",
    "    os.makedirs(\"ris/plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open cleaned data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open cleaned data file\n",
    "data = pd.HDFStore(\"../cleaning/ris/OUT-cleaned.h5\", mode=\"r\")\n",
    "#print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize classification parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "INTERVAL_LENGTH = 100\n",
    "OPERATING_DAY_LIST = [\"091\", \"092\", \"093\", \"094\", \"095\", \"096\", \"097\", \"098\", \"099\", \"100\", \"101\", \"102\", \"103\", \"104\", \"105\"]\n",
    "DETECTOR_LIST = [\"143-5\", \"143-6\", \"143-7\"]\n",
    "\n",
    "# Load parameters and status from a toml file\n",
    "STATUS = toml.load(\"status.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "### Define the classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify():\n",
    "    \n",
    "    # Clear previous output\n",
    "    clear_output(wait=True)\n",
    "    print(\"ACTUAL STATUS:\\n\", STATUS)\n",
    "\n",
    "    # Choose random operating day and detector\n",
    "    OD = choice(OPERATING_DAY_LIST)\n",
    "    DET = choice(DETECTOR_LIST)\n",
    "    CHOICE = \"/\" + OD + \"/\" + DET\n",
    "\n",
    "    if len(data[CHOICE][\"time_cleaned\"]) % 2 == 0:\n",
    "        limit_interval = 1.1 * np.median(data[CHOICE][\"time_cleaned\"][1::2].to_numpy() - data[CHOICE][\"time_cleaned\"][::2].to_numpy())\n",
    "    else:\n",
    "        limit_interval = 1.1 * np.median(data[CHOICE][\"time_cleaned\"][1::2].to_numpy() - data[CHOICE][\"time_cleaned\"][:-1:2].to_numpy())\n",
    "\n",
    "    # Choose a random starting point. If the difference in time is too big, it means I'm taking the data over a \"hole\".\n",
    "    print(\"\\nEXTRACTING DATA FROM: OPERATING DAY \" + OD + \" - DETECTOR \" + DET)\n",
    "    print(\"Searching interval...\")\n",
    "    i = 1\n",
    "    print(\"Attempt:\", i, \"\\r\", end=\"\")\n",
    "    begin = int((len(data[CHOICE][\"time_cleaned\"]) - 200) * np.random.random())\n",
    "    end = begin + INTERVAL_LENGTH\n",
    "    while((data[CHOICE][\"time_cleaned\"][end] - data[CHOICE][\"time_cleaned\"][begin]) > INTERVAL_LENGTH * limit_interval):\n",
    "        i += 1\n",
    "        print(\"Attempt:\", i, \"\\r\", end=\"\")\n",
    "        begin = int((len(data[CHOICE][\"time_cleaned\"]) - 200) * np.random.random())\n",
    "        end = begin + INTERVAL_LENGTH\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(1)\n",
    "    plt.plot(data[CHOICE][\"time_cleaned\"][begin:end], data[CHOICE][\"data_cleaned\"][begin:end], marker='.', linestyle='dashed')\n",
    "    plt.show()\n",
    "\n",
    "    # Classify\n",
    "    print(\"\\n\\nStep:\", STATUS[\"N\"])\n",
    "    answer = input(\"Do you see a glitch? [ yes (y) | no (n) | long (l) | not sure (s) | beautiful glitch (yb) | beautiful no-glitch (nb) | beautiful long (lb) ]\\nType 'exit' to interrupt.\")\n",
    "\n",
    "    if answer == \"y\":\n",
    "        print(\"Glitch detected.\")\n",
    "        # Update status\n",
    "        STATUS[\"N_GLITCH\"] += 1\n",
    "        STATUS[\"N\"] += 1\n",
    "        # Save data\n",
    "        dataname = \"GLITCH/\" + str(STATUS[\"N_GLITCH\"])\n",
    "        with pd.HDFStore(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file.put(dataname, pd.DataFrame({\"time\": data[CHOICE][\"time_cleaned\"][begin:end], \"data\": data[CHOICE][\"data_cleaned\"][begin:end],}, columns=[\"time\", \"data\"]))\n",
    "        with h5py.File(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file[dataname].attrs[\"TITLE\"] = np.string_(\"From: \" + CHOICE)\n",
    "            out_file[dataname].attrs[\"VERSION\"] = np.string_(\"Date: \" + pytime.asctime() + \" | Script name: classification.ipynb | Script commit ID: \" + subprocess.run([\"git\", \"log\", \"-1\", \"--format=%H\", \"classification.ipynb\"], stdout=subprocess.PIPE).stdout.decode(\"ASCII\").rstrip())   \n",
    "\n",
    "    elif answer == \"yb\":\n",
    "        print(\"Glitch detected; saved.\")\n",
    "        # Update status\n",
    "        STATUS[\"N_GLITCH\"] += 1\n",
    "        STATUS[\"N\"] += 1\n",
    "        # Save data\n",
    "        dataname = \"GLITCH/\" + str(STATUS[\"N_GLITCH\"])\n",
    "        with pd.HDFStore(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file.put(dataname, pd.DataFrame({\"time\": data[CHOICE][\"time_cleaned\"][begin:end], \"data\": data[CHOICE][\"data_cleaned\"][begin:end],}, columns=[\"time\", \"data\"]))\n",
    "        with h5py.File(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file[dataname].attrs[\"TITLE\"] = np.string_(\"From: \" + CHOICE)\n",
    "            out_file[dataname].attrs[\"VERSION\"] = np.string_(\"Date: \" + pytime.asctime() + \" | Script name: classification.ipynb | Script commit ID: \" + subprocess.run([\"git\", \"log\", \"-1\", \"--format=%H\", \"classification.ipynb\"], stdout=subprocess.PIPE).stdout.decode(\"ASCII\").rstrip())   \n",
    "        # Save plot\n",
    "        plt.figure(2)\n",
    "        plt.plot(data[CHOICE][\"time_cleaned\"][begin:end], data[CHOICE][\"data_cleaned\"][begin:end], marker='.', linestyle='dashed')\n",
    "        plt.title(\"Glitch \" + str(STATUS[\"N_GLITCH\"]))\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.ylabel(\"Signal [T_cmb V / W]\")\n",
    "        plt.savefig(\"ris/plots/glitch-\" + str(STATUS[\"N_GLITCH\"]) + \".png\", dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    elif answer == \"n\":\n",
    "        print('No glitch detected.')\n",
    "        # Update status\n",
    "        STATUS[\"N_NO_GLITCH\"] += 1\n",
    "        STATUS[\"N\"] += 1\n",
    "        # Save data\n",
    "        dataname = \"NO_GLITCH/\" + str(STATUS[\"N_NO_GLITCH\"])\n",
    "        with pd.HDFStore(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file.put(dataname, pd.DataFrame({\"time\": data[CHOICE][\"time_cleaned\"][begin:end], \"data\": data[CHOICE][\"data_cleaned\"][begin:end],}, columns=[\"time\", \"data\"]))\n",
    "        with h5py.File(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file[dataname].attrs[\"TITLE\"] = np.string_(\"From: \" + CHOICE)\n",
    "            out_file[dataname].attrs[\"VERSION\"] = np.string_(\"Date: \" + pytime.asctime() + \" | Script name: classification.ipynb | Script commit ID: \" + subprocess.run([\"git\", \"log\", \"-1\", \"--format=%H\", \"classification.ipynb\"], stdout=subprocess.PIPE).stdout.decode(\"ASCII\").rstrip())   \n",
    "\n",
    "    elif answer == \"nb\":\n",
    "        print(\"No glitch detected; saved.\")\n",
    "        # Update status\n",
    "        STATUS[\"N_NO_GLITCH\"] += 1\n",
    "        STATUS[\"N\"] += 1\n",
    "        # Save data\n",
    "        dataname = \"NO_GLITCH/\" + str(STATUS[\"N_NO_GLITCH\"])\n",
    "        with pd.HDFStore(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file.put(dataname, pd.DataFrame({\"time\": data[CHOICE][\"time_cleaned\"][begin:end], \"data\": data[CHOICE][\"data_cleaned\"][begin:end],}, columns=[\"time\", \"data\"]))\n",
    "        with h5py.File(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file[dataname].attrs[\"TITLE\"] = np.string_(\"From: \" + CHOICE)\n",
    "            out_file[dataname].attrs[\"VERSION\"] = np.string_(\"Date: \" + pytime.asctime() + \" | Script name: classification.ipynb | Script commit ID: \" + subprocess.run([\"git\", \"log\", \"-1\", \"--format=%H\", \"classification.ipynb\"], stdout=subprocess.PIPE).stdout.decode(\"ASCII\").rstrip())   \n",
    "        # Save plot\n",
    "        plt.figure(2)\n",
    "        plt.plot(data[CHOICE][\"time_cleaned\"][begin:end], data[CHOICE][\"data_cleaned\"][begin:end], marker='.', linestyle='dashed')\n",
    "        plt.title(\"No glitch \" + str(STATUS[\"N_NO_GLITCH\"]))\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.ylabel(\"Signal [T_cmb V / W]\")\n",
    "        plt.savefig(\"ris/plots/no_glitch-\" + str(STATUS[\"N_NO_GLITCH\"]) + \".png\", dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    elif answer == \"l\":\n",
    "        print(\"Long glitch detected.\")\n",
    "        # Update status\n",
    "        STATUS[\"N_LONG\"] += 1\n",
    "        STATUS[\"N\"] += 1\n",
    "        # Save data\n",
    "        dataname = \"LONG_GLITCH/\" + str(STATUS[\"N_LONG\"])\n",
    "        with pd.HDFStore(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file.put(dataname, pd.DataFrame({\"time\": data[CHOICE][\"time_cleaned\"][begin:end], \"data\": data[CHOICE][\"data_cleaned\"][begin:end],}, columns=[\"time\", \"data\"]))\n",
    "        with h5py.File(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file[dataname].attrs[\"TITLE\"] = np.string_(\"From: \" + CHOICE)\n",
    "            out_file[dataname].attrs[\"VERSION\"] = np.string_(\"Date: \" + pytime.asctime() + \" | Script name: classification.ipynb | Script commit ID: \" + subprocess.run([\"git\", \"log\", \"-1\", \"--format=%H\", \"classification.ipynb\"], stdout=subprocess.PIPE).stdout.decode(\"ASCII\").rstrip())   \n",
    "\n",
    "    elif answer == \"lb\":\n",
    "        print('Long glitch detected; saved.')\n",
    "        # Update status\n",
    "        STATUS[\"N_LONG\"] += 1\n",
    "        STATUS[\"N\"] += 1\n",
    "        # Save data\n",
    "        dataname = \"LONG_GLITCH/\" + str(STATUS[\"N_LONG\"])\n",
    "        with pd.HDFStore(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file.put(dataname, pd.DataFrame({\"time\": data[CHOICE][\"time_cleaned\"][begin:end], \"data\": data[CHOICE][\"data_cleaned\"][begin:end],}, columns=[\"time\", \"data\"]))\n",
    "        with h5py.File(\"ris/OUT-classified.h5\") as out_file:\n",
    "            out_file[dataname].attrs[\"TITLE\"] = np.string_(\"From: \" + CHOICE)\n",
    "            out_file[dataname].attrs[\"VERSION\"] = np.string_(\"Date: \" + pytime.asctime() + \" | Script name: classification.ipynb | Script commit ID: \" + subprocess.run([\"git\", \"log\", \"-1\", \"--format=%H\", \"classification.ipynb\"], stdout=subprocess.PIPE).stdout.decode(\"ASCII\").rstrip())   \n",
    "        # Save plot\n",
    "        plt.figure(2)\n",
    "        plt.plot(data[CHOICE][\"time_cleaned\"][begin:end], data[CHOICE][\"data_cleaned\"][begin:end], marker='.', linestyle='dashed')\n",
    "        plt.title(\"Long glitch \" + str(STATUS[\"N_LONG\"]))\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.ylabel(\"Signal [T_cmb V / W]\")\n",
    "        plt.savefig(\"ris/plots/long_glitch-\" + str(STATUS[\"N_LONG\"]) + \".png\", dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "    elif answer == \"exit\":\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        print('Unable to classify.')\n",
    "\n",
    "    # Save parameters\n",
    "    with open(\"status.toml\", mode=\"w\") as toml_status_file:\n",
    "        toml.dump(STATUS, toml_status_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify\n",
    "\n",
    "Now run this function how many times you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while classify() != \"exit\":\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminate the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close data file\n",
    "data.close()\n",
    "\n",
    "# Print \"OUT-classified.h5\" informations\n",
    "with pd.HDFStore(\"ris/OUT-classified.h5\") as out_file:\n",
    "    print(out_file.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset the classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "answer = input(\"Are you sure?\")\n",
    "if answer == \"yes\":\n",
    "    answer = input(\"This will delete 'plots' folder and 'OUT-classified.h5' file!\")\n",
    "    if answer == \"yes\":\n",
    "        # Remove classified data\n",
    "        import os\n",
    "        import shutil\n",
    "        if os.path.exists(\"ris/plots\"):\n",
    "            shutil.rmtree(\"ris/plots\")\n",
    "        if os.path.exists(\"ris/OUT-classified.h5\"):\n",
    "            os.remove(\"ris/OUT-classified.h5\")\n",
    "        # Reset status\n",
    "        N = 0\n",
    "        N_GLITCH = 0\n",
    "        N_LONG = 0\n",
    "        N_NO_GLITCH = 0\n",
    "        toml_status_dict = {\"N\": N, \"N_GLITCH\": N_GLITCH, \"N_LONG\": N_LONG, \"N_NO_GLITCH\": N_NO_GLITCH}\n",
    "        with open(\"status.toml\", mode=\"w\") as toml_status_file:\n",
    "            import toml\n",
    "            toml.dump(toml_status_dict, toml_status_file)\n",
    "        print(\"DONE.\")\n",
    "        # Restart kernel\n",
    "        os._exit(0)\n",
    "    else:\n",
    "        print(\"ABORTED.\")\n",
    "else:\n",
    "    print(\"ABORTED.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
