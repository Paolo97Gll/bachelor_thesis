{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFY DATA\n",
    "\n",
    "Classify data for machine learning algorithm training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import toml\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toml generators\n",
    "### Parameter generator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#I set number of points displayed per random graph\n",
    "INTERVAL_LENGTH = 100\n",
    "\n",
    "# Operating day list\n",
    "OPERATING_DAY_LIST = []\n",
    "for OPERATING_DAY in range(91,106):\n",
    "    if OPERATING_DAY < 100:\n",
    "        OPERATING_DAY_LIST.append(\"0\" + str(OPERATING_DAY))\n",
    "    else:\n",
    "        OPERATING_DAY_LIST.append(str(OPERATING_DAY))\n",
    "        \n",
    "# Detector list\n",
    "DETECTOR_LIST = [\"143-5\", \"143-6\", \"143-7\"]\n",
    "\n",
    "toml_parameters_dict = {\"INTERVAL_LENGTH\": INTERVAL_LENGTH, \"OPERATING_DAY_LIST\": OPERATING_DAY_LIST, \"DETECTOR_LIST\": DETECTOR_LIST}\n",
    "with open(\"parameters.toml\", mode=\"w\") as toml_parameters_file:\n",
    "    toml.dump(toml_parameters_dict, toml_parameters_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status generator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "N = 0\n",
    "N_GLITCH = 0\n",
    "N_LONG = 0\n",
    "N_NO_GLITCH = 0\n",
    "\n",
    "toml_status_dict = {\"N\": N, \"N_GLITCH\": N_GLITCH, \"N_LONG\": N_LONG, \"N_NO_GLITCH\": N_NO_GLITCH}\n",
    "with open(\"status.toml\", mode=\"w\") as toml_status_file:\n",
    "    toml.dump(toml_status_dict, toml_status_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Open cleaned data file and initialize classification parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open cleaned data file\n",
    "data = pd.HDFStore(\"../cleaning/ris/OUT-cleaned.h5\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters and status from a toml file\n",
    "PARAMETERS = toml.load(\"parameters.toml\")\n",
    "STATUS = toml.load(\"status.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "begin = 0\n",
    "end = len(time_clean)-1\n",
    "\n",
    "n = 0\n",
    "N_GLITCH = 0\n",
    "N_LONG = 0\n",
    "N_NO_GLITCH = 0\n",
    "\n",
    "while(n<2000):\n",
    "    \n",
    "    begin = 0\n",
    "    end = len(time_clean)-1\n",
    "    #choose a random starting point. If the difference in time is too big, it means I'm taking the data over a \"hole\".\n",
    "    while((time_clean[end] - time_clean[begin]) > INTERVAL_LENGTH * limit_interval):\n",
    "        begin = int((len(time_clean)-301)*np.random.random_sample())\n",
    "        end = begin + INTERVAL_LENGTH\n",
    "    \n",
    "    #plot the data\n",
    "    plt.figure(1)\n",
    "    plt.plot(time_clean[begin:end], clean_data[begin:end], marker='.', linestyle='dashed', color='#6a97be', alpha=1)\n",
    "    plt.show()\n",
    "    print('--Step number: ', n)\n",
    "    print('Do you see a glitch? [ yes (y) / no (n) / long (q) / not sure (s) / beautiful glitch (b) / beautiful no-glitch (a) / beautiful long (z)]')\n",
    "    answer = input()\n",
    "\n",
    "    if(answer == 'y'):\n",
    "        print('Glitch detected.')\n",
    "        N_GLITCH = N_GLITCH + 1\n",
    "        n = n+1\n",
    "        OUTPUT_FILE = (\"Train Data/glitch/train_\" + str(N_GLITCH) +\".txt\")\n",
    "        #healpy.write_map(OUTPUT_FILE, clean_data[begin:end], coord='E')\n",
    "        # There's something wrong with the line of code above. I will try to figure out why later.\n",
    "        np.savetxt(OUTPUT_FILE, (time_clean[begin:end], clean_data[begin:end]))\n",
    "    elif(answer == 'b'):\n",
    "        print('Glitch detected. So beautiful I save the plot.')\n",
    "        N_GLITCH = N_GLITCH + 1\n",
    "        n = n+1\n",
    "        OUTPUT_FILE = (\"Train Data/glitch/train_\" + str(N_GLITCH) +\".txt\")\n",
    "        \n",
    "        plt.figure(2)\n",
    "        plt.plot(time_clean[begin:end], clean_data[begin:end], marker='.', linestyle='dashed', color='blue', alpha=1)\n",
    "        plt.savefig(\"plots/glitch\" + str(N_GLITCH) + \".png\", dpi=600)\n",
    "        \n",
    "        np.savetxt(OUTPUT_FILE, (time_clean[begin:end], clean_data[begin:end]))\n",
    "\n",
    "    elif(answer == 'n'):\n",
    "        print('No glitch detected.')\n",
    "        N_NO_GLITCH = N_NO_GLITCH + 1\n",
    "        n = n+1\n",
    "        OUTPUT_FILE = (\"Train Data/no_glitch/train_\" + str(N_NO_GLITCH) +\".txt\")\n",
    "        np.savetxt(OUTPUT_FILE, (time_clean[begin:end], clean_data[begin:end]))\n",
    "\n",
    "    elif(answer == 'a'):\n",
    "        print('No glitch detected. So beautiful I save the plot.')\n",
    "        N_NO_GLITCH = N_NO_GLITCH + 1\n",
    "        n = n+1\n",
    "        OUTPUT_FILE = (\"Train Data/no_glitch/train_\" + str(N_NO_GLITCH) +\".txt\")\n",
    "        \n",
    "        plt.figure(2)\n",
    "        plt.plot(time_clean[begin:end], clean_data[begin:end], marker='.', linestyle='dashed', color='blue', alpha=1)\n",
    "        plt.savefig(\"plots/no_glitch\" + str(N_NO_GLITCH) + \".png\", dpi=600)\n",
    "        \n",
    "        np.savetxt(OUTPUT_FILE, (time_clean[begin:end], clean_data[begin:end]))\n",
    "\n",
    "    elif(answer == 'q'):\n",
    "        print('Long glitch detected.')\n",
    "        N_LONG = N_LONG + 1\n",
    "        n = n+1\n",
    "        OUTPUT_FILE = (\"Train Data/long_glitch/train_\" + str(N_LONG) +\".txt\")\n",
    "\n",
    "        np.savetxt(OUTPUT_FILE, (time_clean[begin:end], clean_data[begin:end]))\n",
    "\n",
    "\n",
    "    elif(answer == 'z'):\n",
    "        print('Long glitch detected. So beautiful I save the plot.')\n",
    "        N_LONG = N_LONG + 1\n",
    "        n = n+1\n",
    "        OUTPUT_FILE = (\"Train Data/long_glitch/train_\" + str(N_LONG) +\".txt\")\n",
    "        \n",
    "        plt.figure(2)\n",
    "        plt.plot(time_clean[begin:end], clean_data[begin:end], marker='.', linestyle='dashed', color='blue', alpha=1)\n",
    "        plt.savefig(\"plots/long_glitch\" + str(N_LONG) + \".png\", dpi=600)\n",
    "\n",
    "        np.savetxt(OUTPUT_FILE, (time_clean[begin:end], clean_data[begin:end]))\n",
    "    else:\n",
    "        print('Unable to classify.')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
