{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune LightGBM hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T11:00:09.183364Z",
     "start_time": "2019-12-07T11:00:09.167793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading files\n",
    "import toml\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "## Model\n",
    "import lightgbm as lgb\n",
    "# Hyper-parameter optimizers\n",
    "from hyperopt import hp\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import tpe\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Other\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T10:46:46.816749Z",
     "start_time": "2019-12-07T10:46:46.676104Z"
    }
   },
   "outputs": [],
   "source": [
    "first_cycle = True\n",
    "with pd.HDFStore('../../classification/ris/OUT-classified-merged.h5', mode='r') as in_data:\n",
    "    for group in ['GLITCH', 'NO_GLITCH']:\n",
    "        if first_cycle == True:\n",
    "            data = np.array(in_data[group].to_numpy())\n",
    "            if group == 'GLITCH':\n",
    "                target = np.ones(len(data))\n",
    "            elif group == 'NO_GLITCH':\n",
    "                target = np.zeros(len(data))\n",
    "            else:\n",
    "                print(\"ERROR.\")\n",
    "            first_cycle = False\n",
    "        else:\n",
    "            data = np.concatenate((data, in_data[group].to_numpy()))\n",
    "            if group == 'GLITCH':\n",
    "                target = np.concatenate((target, np.ones(len(in_data[group].to_numpy()))))\n",
    "            elif group == 'NO_GLITCH':\n",
    "                target = np.concatenate((target, np.zeros(len(in_data[group].to_numpy()))))\n",
    "            else:\n",
    "                print(\"ERROR.\")\n",
    "    data = np.concatenate((data, in_data['MULTI_GLITCH'].to_numpy()))\n",
    "    target = np.concatenate((target, np.ones(len(in_data['MULTI_GLITCH'].to_numpy()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T08:56:32.435957Z",
     "start_time": "2019-12-07T08:56:32.423143Z"
    }
   },
   "source": [
    "If you want to sort the data, run the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.sort(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T10:46:46.832418Z",
     "start_time": "2019-12-07T10:46:46.816749Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data['target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T10:46:46.848030Z",
     "start_time": "2019-12-07T10:46:46.832418Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyper-parameters space and other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T10:46:47.523028Z",
     "start_time": "2019-12-07T10:46:47.492275Z"
    }
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'num_leaves': 2 + hp.randint('num_leaves', 150),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'min_data_in_leaf': 2 + hp.randint('min_data_in_leaf', 300)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T10:46:48.080431Z",
     "start_time": "2019-12-07T10:46:48.041755Z"
    }
   },
   "outputs": [],
   "source": [
    "tpe_algorithm = tpe.suggest\n",
    "bayes_trials = Trials()\n",
    "MAX_EVALS = 20\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T10:46:48.591486Z",
     "start_time": "2019-12-07T10:46:48.550674Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Tuning\"\"\"\n",
    "    # Perform n_fold cross validation with hyperparameters\n",
    "    # Use early stopping and evalute based on ROC AUC\n",
    "    cv_results = lgb.cv(params, lgb_train, nfold = n_folds, num_boost_round = 10000, early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "    # Extract the best score\n",
    "    best_score = max(cv_results['auc-mean'])\n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T09:09:43.211693Z",
     "start_time": "2019-12-07T09:09:43.189052Z"
    }
   },
   "source": [
    "Run the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T10:54:59.056042Z",
     "start_time": "2019-12-07T10:46:49.726302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 20/20 [08:09<00:00, 24.47s/it, best loss: 0.03658412578604486]\n",
      "Best result: {'learning_rate': 0.13343406638866043, 'min_data_in_leaf': 6, 'num_leaves': 22}\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(X, y)\n",
    "\n",
    "# Optimize\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = MAX_EVALS, trials = bayes_trials)\n",
    "\n",
    "# Print result\n",
    "# On screen\n",
    "print('Best result:', best)\n",
    "# On file\n",
    "with open('ris/HyperOpt_out.md', mode='a') as f:\n",
    "    print('# ' + time.ctime(), file=f)\n",
    "    print('', file=f)\n",
    "    print('### HyperOpt best result:', file=f)\n",
    "    print('', file=f)\n",
    "    print('```python', file=f)\n",
    "    print(best, file=f)\n",
    "    print('```', file=f)\n",
    "    print('', file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T11:10:03.743200Z",
     "start_time": "2019-12-07T11:06:53.597360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8847117794486216 +- 0.0\n"
     ]
    }
   ],
   "source": [
    "# k-fold parameters\n",
    "n_splits = 5\n",
    "n_repeats = 6\n",
    "\n",
    "# Stratified k-fold\n",
    "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=None)\n",
    "scores = np.array([])\n",
    "# Make k-fold CV\n",
    "i = 1\n",
    "new_X, new_y = np.array(X.to_numpy()), np.array(y.to_numpy())\n",
    "for train_index, test_index in rskf.split(new_X, new_y):\n",
    "    print(i, 'su', n_splits*n_repeats, '\\r', end='')\n",
    "    # Split\n",
    "    X_train, X_test = new_X[train_index], new_X[test_index]\n",
    "    y_train, y_test = new_y[train_index], new_y[test_index]\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "    # Train\n",
    "    evals_result = {} \n",
    "    gbm = lgb.train(best,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=1000,\n",
    "                    valid_sets=[lgb_train, lgb_test],\n",
    "                    evals_result=evals_result,\n",
    "                    verbose_eval=False)\n",
    "    # Test\n",
    "    ris = gbm.predict(X_test)\n",
    "    # Change into discrete values (yes or no)\n",
    "    ris[ris>=0.5] = 1\n",
    "    ris[ris<0.5] = 0\n",
    "    # Score\n",
    "    scores = accuracy_score(y_test, ris)\n",
    "    i += 1\n",
    "\n",
    "# Print final score\n",
    "# On screen\n",
    "print('Score:', scores.mean(), '+-', scores.std())\n",
    "# On file\n",
    "with open('ris/HyperOpt_out.md', mode='a') as f:\n",
    "    print('### Score:', file=f)\n",
    "    print('', file=f)\n",
    "    print('```python', file=f)\n",
    "    print('Score:', scores.mean(), '+-', scores.std(), file=f)\n",
    "    print('```', file=f)\n",
    "    print('', file=f)\n",
    "    print('', file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send Telegram message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T11:10:04.214056Z",
     "start_time": "2019-12-07T11:10:03.743200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send telegram message\n",
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] LGB HyperOpt terminated.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
