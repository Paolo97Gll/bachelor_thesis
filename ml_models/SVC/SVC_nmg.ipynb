{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC - No multi glitch\n",
    "\n",
    "**N.B.** SVC require normalized data; nevertheless, in this case _we can't normalize the features_, otherwise we would lose all the information on the peaks!! In fact, if we do not normalize the data, the train score is around $0.98$ or $0.99$; on the contrary, if we normalize the data, the train score is around $0.70$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "#sns.set_context('paper')\n",
    "\n",
    "# Machine Learning\n",
    "# Model\n",
    "from sklearn.svm import SVC\n",
    "# Ensemble model\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Splitter Classes\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# Splitter Functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "# Model validation\n",
    "from sklearn.model_selection import learning_curve\n",
    "# Training metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Other\n",
    "import requests\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `print_confusion_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    columnwidth = max([len(str(x)) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t\\p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `plot_confusion_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, labels, title, filename, normalize=True, save=True):\n",
    "    # Create DataFrame\n",
    "    df_cm = pd.DataFrame(cm, columns=labels, index=labels)\n",
    "    df_cm.index.name = 'True label'\n",
    "    df_cm.columns.name = 'Predicted label'\n",
    "    \n",
    "    # Normalize\n",
    "    if normalize:\n",
    "        df_cm = df_cm.div(df_cm.sum(axis=1), axis=0).round(decimals=2)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = sns.heatmap(df_cm, cmap='Blues', annot=True)\n",
    "    axlim = ax.get_ylim()\n",
    "    ax.set_ylim(axlim[0] + 0.5, axlim[1] - 0.5)\n",
    "    if normalize:\n",
    "        ax.set_title(title + ' (normalized)')\n",
    "    else:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    if save == True:\n",
    "        fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `plot_learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X, y, title, filename, ylim=None, xscale=None, cv=None,\n",
    "                        n_jobs=-1, n_curve_steps=20, save=True):\n",
    "    train_sizes = np.linspace(.1, 1.0, n_curve_steps)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    if xscale is not None:\n",
    "        plt.xscale(xscale)\n",
    "    plt.xlabel('Training dataset size')\n",
    "    plt.ylabel('Score')\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color='r')\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color='g')\n",
    "    plt.plot(train_sizes, train_scores_mean, linestyle='--', color='r',\n",
    "             label='Training score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='g',\n",
    "             label='Cross-validation score')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `plot_roc_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(estimator, X, y, cv, title, filename, save=True):\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, y):\n",
    "        probas_ = estimator.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "        i += 1\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "Load data and target from `classification/ris/OUT-classified-merged.h5` and load into numpy arrays.\n",
    "- **Label `0` = NO GLITCH**\n",
    "- **Label `1` = GLITCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "first_cycle = True\n",
    "with pd.HDFStore('../../classification/ris/OUT-classified-merged.h5', mode='r') as in_data:\n",
    "    for group in ['GLITCH', 'NO_GLITCH']:\n",
    "        if first_cycle == True:\n",
    "            data = np.array(in_data[group].to_numpy())\n",
    "            if group == 'GLITCH':\n",
    "                target = np.ones(len(data))\n",
    "            elif group == 'NO_GLITCH':\n",
    "                target = np.zeros(len(data))\n",
    "            else:\n",
    "                print(\"ERROR.\")\n",
    "            first_cycle = False\n",
    "        else:\n",
    "            data = np.concatenate((data, in_data[group].to_numpy()))\n",
    "            if group == 'GLITCH':\n",
    "                target = np.concatenate((target, np.ones(len(in_data[group].to_numpy()))))\n",
    "            elif group == 'NO_GLITCH':\n",
    "                target = np.concatenate((target, np.zeros(len(in_data[group].to_numpy()))))\n",
    "            else:\n",
    "                print(\"ERROR.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard training\n",
    "\n",
    "Initialize best hyper-parameters founded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel = 'rbf'\n",
    "best_gamma = 0.0145\n",
    "best_C = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Use k-fold to make a cross validation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# Multithreading\n",
    "maxthreads = 8\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "c = threading.Condition()\n",
    "\n",
    "# k-fold parameters\n",
    "n_splits = 5\n",
    "n_repeats = 10\n",
    "\n",
    "# Multithread function\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data\n",
    "    global target\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_test, y_test)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, train_score)\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "\n",
    "# Stratified k-fold\n",
    "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data, target):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "    \n",
    "# Print final score\n",
    "print('Score:', scores.mean(), '+-', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix, learning curve and ROC curve\n",
    "\n",
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=14, stratify=target)\n",
    "# Train and predict\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "labels = [0., 1.]\n",
    "labels_text = ['no glitch', 'glitch']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Print confusion matrix\n",
    "print('Text confusion matrix (without normalization)\\n')\n",
    "print_confusion_matrix(cm, labels_text)\n",
    "print('\\n\\nGraphic confusion matrix (normalized)\\n')\n",
    "plot_confusion_matrix(cm, labels_text, 'Confusion matrix (no multi glitch)', 'ris/plots/nmg-confusion_matrix.pdf', normalize=True, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "\n",
    "# Plot learning curve\n",
    "plot_learning_curve(clf, data, target, 'Learning curve (no multi glitch)', 'ris/plots/nmg-learning_curve.pdf', cv=cv, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C, probability=True)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(clf, data, target, cv, 'ROC curve (no multi glitch)', 'ris/plots/nmg-roc_curve.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T09:32:39.445374Z",
     "start_time": "2019-09-28T09:32:39.442706Z"
    }
   },
   "source": [
    "# Sorted data\n",
    "\n",
    "Glitches data have a peak, but it is in a random point of the plot. We can help the model by sorting data values: the new features queue will be about the same for all the data, while the first features will became discriminant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s = np.sort(data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize best hyper-parameters founded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel = 'linear'\n",
    "best_C = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Use k-fold to make a cross validation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# Multithreading\n",
    "maxthreads = 8\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "c = threading.Condition()\n",
    "\n",
    "# k-fold parameters\n",
    "n_splits = 5\n",
    "n_repeats = 10\n",
    "\n",
    "# Multithread function\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data\n",
    "    global target\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, C=best_C)\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_test, y_test)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, train_score)\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "\n",
    "# Stratified k-fold\n",
    "rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data, target):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "    \n",
    "# Print final score\n",
    "print('Score:', scores.mean(), '+-', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix, learning curve and ROC curve\n",
    "\n",
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=14, stratify=target)\n",
    "# Train and predict\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "labels = [0., 1.]\n",
    "labels_text = ['no glitch', 'glitch']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Print confusion matrix\n",
    "print('Text confusion matrix (without normalization)\\n')\n",
    "print_confusion_matrix(cm, labels_text)\n",
    "print('\\n\\nGraphic confusion matrix (normalized)\\n')\n",
    "plot_confusion_matrix(cm, labels_text, 'Confusion matrix (no multi glitch) (sorted)', 'ris/plots/nmg_s-confusion_matrix.pdf', normalize=True, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "\n",
    "# Plot learning curve\n",
    "plot_learning_curve(clf, data, target, 'Learning curve (no multi glitch) (sorted)', 'ris/plots/nmg_s-learning_curve.pdf', cv=cv, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C, probability=True)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(clf, data, target, cv, 'ROC curve (no multi glitch) (sorted)', 'ris/plots/nmg_s-roc_curve.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorted data (and absolute value)\n",
    "\n",
    "Glitches data have a peak, but it is in a random point of the plot. We can help the model by sorting data values: the new features queue will be about the same for all the data, while the first features will became discriminant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sa = np.abs(np.sort(data, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-normalized data\n",
    "\n",
    "Initialize best hyper-parameters founded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel = 'rbf'\n",
    "best_gamma = 0.0145\n",
    "best_C = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "Use k-fold to make a cross validation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     10
    ]
   },
   "outputs": [],
   "source": [
    "# Multithreading\n",
    "maxthreads = 8\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "c = threading.Condition()\n",
    "\n",
    "# k-fold parameters\n",
    "n_splits = 5\n",
    "n_repeats = 10\n",
    "\n",
    "# Multithread function\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data_sa\n",
    "    global target\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "    X_train, X_test = data_sa[train_index], data_sa[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_test, y_test)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, train_score)\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "\n",
    "# Stratified k-fold\n",
    "means = np.array([])\n",
    "for i in range(n_repeats):\n",
    "    rskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=None)\n",
    "    scores = np.array([])\n",
    "    threads = []\n",
    "    # Make k-fold CV\n",
    "    for train_index, test_index in rskf.split(data_sa, target):\n",
    "        thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    means = np.append(means, scores.mean())\n",
    "    \n",
    "# Print final score\n",
    "print('Score:', means.mean(), '+-', means.std() / np.sqrt(n_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix, learning curve and ROC curve\n",
    "\n",
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_sa, target, test_size=0.3, random_state=14, stratify=target)\n",
    "# Train and predict\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "labels = [0., 1.]\n",
    "labels_text = ['no glitch', 'glitch']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Print confusion matrix\n",
    "print('Text confusion matrix (without normalization)\\n')\n",
    "print_confusion_matrix(cm, labels_text)\n",
    "print('\\n\\nGraphic confusion matrix (normalized)\\n')\n",
    "plot_confusion_matrix(cm, labels_text, 'Confusion matrix (no multi glitch)', 'ris/plots/confusion_matrix.pdf', normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "\n",
    "# Plot learning curve\n",
    "plot_learning_curve(clf, data_sa, target, 'Learning curve (no multi glitch)', 'ris/plots/learning_curve.pdf', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C, probability=True)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(clf, data_sa, target, cv, 'ROC curve (no multi glitch)', 'ris/plots/roc_curve.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "Data augmentation is a strategy that increase the diversity of data available for training models, without actually collecting new data. The data augmentation techniques used in this situation are vertical flipping and translation.\n",
    "\n",
    "**N.B.: the training time is extremely big!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Due to the long training time, this part will be made in another script on `belen`, called `score_algorithms.py` .\n",
    "\n",
    "### Simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See score_algorithms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier training\n",
    "\n",
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See score_algorithms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix, learning curve and ROC curve\n",
    "\n",
    "Due to the long training time, this part will be made in another script on `belen`, called `data_augmentation_plots.py` .\n",
    "\n",
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See data_augmentation_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See data_augmentation_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See data_augmentation_plots.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YES MULTI GLITCH\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Load data and target from `classification/ris/OUT-classified-merged.h5` and load into numpy arrays.\n",
    "\n",
    "**Label `0` = NO GLITCH**\n",
    "\n",
    "**Label `1` = GLITCH and MULTI GLITCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('../../classification/ris/OUT-classified-merged.h5', mode='r') as in_data:\n",
    "    data = np.concatenate((data, in_data['MULTI_GLITCH'].to_numpy()))\n",
    "    target = np.concatenate((target, np.ones(len(in_data['MULTI_GLITCH'].to_numpy()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best training\n",
    "\n",
    "Initialize best hyper-parameters founded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel = 'rbf'\n",
    "best_gamma = 0.0151\n",
    "best_C = 1.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "Use k-fold to make a cross validation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multithreading\n",
    "maxthreads = 8\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "c = threading.Condition()\n",
    "\n",
    "# k-fold parameters\n",
    "n_splits = 5\n",
    "n_repeats = 10\n",
    "\n",
    "# Multithread function\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data\n",
    "    global target\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_test, y_test)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, train_score)\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "\n",
    "# Stratified k-fold\n",
    "means = np.array([])\n",
    "for i in range(n_repeats):\n",
    "    rskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=None)\n",
    "    scores = np.array([])\n",
    "    threads = []\n",
    "    # Make k-fold CV\n",
    "    for train_index, test_index in rskf.split(data, target):\n",
    "        thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    means = np.append(means, scores.mean())\n",
    "    \n",
    "# Print final score\n",
    "print('Score:', means.mean(), '+-', means.std() / np.sqrt(n_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix, learning curve and ROC curve\n",
    "\n",
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=14, stratify=target)\n",
    "# Train and predict\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "labels = [0., 1.]\n",
    "labels_text = ['no glitch', 'glitch']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Print confusion matrix\n",
    "print('Text confusion matrix (without normalization)\\n')\n",
    "print_confusion_matrix(cm, labels_text)\n",
    "print('\\n\\nGraphic confusion matrix (normalized)\\n')\n",
    "plot_confusion_matrix(cm, labels_text, 'Confusion matrix (no multi glitch)', 'ris/plots/confusion_matrix.pdf', normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "\n",
    "# Plot learning curve\n",
    "plot_learning_curve(clf, data, target, 'Learning curve (no multi glitch)', 'ris/plots/learning_curve.pdf', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C, probability=True)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(clf, data, target, cv, 'ROC curve (no multi glitch)', 'ris/plots/roc_curve.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Data augmentation is a strategy that increase the diversity of data available for training models, without actually collecting new data. The data augmentation techniques used in this situation are vertical flipping and translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug, target_aug = data, target\n",
    "data_aug = np.concatenate((data_aug, -data))\n",
    "target_aug = np.concatenate((target_aug, target))\n",
    "\n",
    "for i in range(1,100):\n",
    "    data_aug = np.concatenate((data_aug, np.roll(data, i, axis=1)))\n",
    "    data_aug = np.concatenate((data_aug, -np.roll(data, i, axis=1)))\n",
    "    target_aug = np.concatenate((target_aug, target))\n",
    "    target_aug = np.concatenate((target_aug, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxthreads = 4\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "c = threading.Condition()\n",
    "\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data_aug\n",
    "    global target_aug\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, clf.score(X_test, y_test))\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "\n",
    "    \n",
    "## K-FOLD\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rkf.split(data_aug, target_aug):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# Print final score\n",
    "print('Average score (k-fold):', scores.mean(), '+-', scores.std())\n",
    "\n",
    "\n",
    "## STRATIFIED K-FOLD\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data_aug, target_aug):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# Print final score\n",
    "print('Average score (Stratified k-fold):', scores.mean(), '+-', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier training\n",
    "\n",
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start Bagging Classifier k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "clf = BaggingClassifier(SVC(kernel=best_kernel, gamma=best_gamma, C=best_C), n_estimators=n_estimators, max_samples=1./n_estimators, n_jobs=-1)\n",
    "\n",
    "\n",
    "## K-FOLD\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores_rkf = np.array([])\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rkf.split(data_aug, target_aug):\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores_rkf = np.append(scores_rkf, clf.score(X_test, y_test))\n",
    "# Print final score\n",
    "print('Average score (k-fold):', scores_rkf.mean(), '+-', scores_rkf.std())\n",
    "\n",
    "\n",
    "## STRATIFIED K-FOLD\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores_rskf = np.array([])\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data_aug, target_aug):\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores_rskf = np.append(scores_rskf, clf.score(X_test, y_test))\n",
    "# Print final score\n",
    "print('Average score (Stratified k-fold):', scores_rskf.mean(), '+-', scores_rskf.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End Bagging Classifier k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End data augmentation part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End yes multi glitch part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "465px",
    "width": "403px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
