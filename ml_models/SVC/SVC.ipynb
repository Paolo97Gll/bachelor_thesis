{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC: C-Support Vector Classification\n",
    "\n",
    "A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side. (from [here](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T21:14:16.912401Z",
     "start_time": "2019-09-25T21:14:14.764257Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Reading files\n",
    "import h5py\n",
    "import toml\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "#sns.set_context('paper')\n",
    "\n",
    "# Machine Learning\n",
    "# Model\n",
    "from sklearn.svm import SVC\n",
    "# Ensemble\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# Splitter Classes\n",
    "#from sklearn.model_selection import KFold\n",
    "#from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# Splitter Functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "# Hyper-parameter optimizers\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "# Model validation\n",
    "from sklearn.model_selection import learning_curve\n",
    "# Training metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `print_confusion_matrix`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-25T16:09:22.321Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def print_confusion_matrix(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    columnwidth = max([len(str(x)) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t\\p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `plot_confusion_matrix`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-25T16:09:22.828Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def plot_confusion_matrix(cm, labels, normalize=True, filename='confusion_matrix.pdf', save=True):\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_cm = pd.DataFrame(cm, columns=labels, index=labels)\n",
    "    df_cm.index.name = 'True label'\n",
    "    df_cm.columns.name = 'Predicted label'\n",
    "    \n",
    "    # Normalize\n",
    "    if normalize:\n",
    "        df_cm = df_cm.div(df_cm.sum(axis=1), axis=0).round(decimals=2)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = sns.heatmap(df_cm, cmap='Blues', annot=True)\n",
    "    axlim = ax.get_ylim()\n",
    "    ax.set_ylim(axlim[0] + 0.5, axlim[1] - 0.5)\n",
    "    if normalize:\n",
    "        ax.set_title('Confusion matrix (with normalization)')\n",
    "    else:\n",
    "        ax.set_title('Confusion matrix (without normalization)')\n",
    "    \n",
    "    if save == True:\n",
    "        fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `plot_learning_curve`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-25T16:09:23.158Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5),\n",
    "                        filename='learning_curve.pdf', save=True):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predbest_test_scorehods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Score')\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    #plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color='r')\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color='g')\n",
    "    plt.plot(train_sizes, train_scores_mean, linestyle='--', color='r',\n",
    "             label='Training score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='g',\n",
    "             label='Cross-validation score')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `plot_roc_curve`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-25T16:09:23.465Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def plot_roc_curve(estimator, cv, filename='ROC_curve.pdf', save=True):\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(data, target):\n",
    "        probas_ = clf.fit(data[train], target[train]).predict_proba(data[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(target[test], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "        i += 1\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO MULTI GLITCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T21:14:18.972239Z",
     "start_time": "2019-09-25T21:14:18.552142Z"
    }
   },
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start no multi glitch part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Load data and target from `classification/ris/OUT-classified-merged.h5` and load into numpy arrays.\n",
    "\n",
    "**Label `0` = NO GLITCH**\n",
    "\n",
    "**Label `1` = GLITCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T21:14:22.250864Z",
     "start_time": "2019-09-25T21:14:21.815221Z"
    }
   },
   "outputs": [],
   "source": [
    "first_cycle = True\n",
    "with pd.HDFStore('../../classification/ris/OUT-classified-merged.h5', mode='r') as in_data:\n",
    "    for group in ['GLITCH', 'NO_GLITCH']:\n",
    "        if first_cycle == True:\n",
    "            data = np.array(in_data[group].to_numpy())\n",
    "            if group == 'GLITCH':\n",
    "                target = np.ones(len(data))\n",
    "            elif group == 'NO_GLITCH':\n",
    "                target = np.zeros(len(data))\n",
    "            else:\n",
    "                print(\"ERROR.\")\n",
    "            first_cycle = False\n",
    "        else:\n",
    "            data = np.concatenate((data, in_data[group].to_numpy()))\n",
    "            if group == 'GLITCH':\n",
    "                target = np.concatenate((target, np.ones(len(in_data[group].to_numpy()))))\n",
    "            elif group == 'NO_GLITCH':\n",
    "                target = np.concatenate((target, np.zeros(len(in_data[group].to_numpy()))))\n",
    "            else:\n",
    "                print(\"ERROR.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best training\n",
    "\n",
    "Initialize best hyper-parameters founded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T21:14:23.722263Z",
     "start_time": "2019-09-25T21:14:23.719206Z"
    }
   },
   "outputs": [],
   "source": [
    "best_kernel = 'rbf'\n",
    "best_gamma = 0.0145\n",
    "best_C = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "Use k-fold to make a cross validation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = 5\n",
    "n_splits = 5\n",
    "\n",
    "# Multithread function\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data\n",
    "    global target\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_test, y_test)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, train_score)\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "\n",
    "# Stratified k-fold\n",
    "means = np.array([])\n",
    "for i in range(n_repeats):\n",
    "    rskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=None)\n",
    "    scores = np.array([])\n",
    "    threads = []\n",
    "    # Make k-fold CV\n",
    "    for train_index, test_index in rskf.split(data, target):\n",
    "        thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    means = np.append(means, scores.mean())\n",
    "    \n",
    "# Print final score\n",
    "print('Average score:', means.mean(), '+-', means.std() / np.sqrt(n_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix, learning curve and ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0, )\n",
    "# Train and predict\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "labels = [0., 1.]\n",
    "labels_text = ['no glitch', 'glitch']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Print confusion matrix\n",
    "print('Text confusion matrix (without normalization)\\n')\n",
    "print_confusion_matrix(cm, labels_text)\n",
    "print('\\n\\nGraphic confusion matrix (normalized)\\n')\n",
    "plot_confusion_matrix(cm, labels_text, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curve"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n",
    "\n",
    "# Plot learning curve\n",
    "plot_learning_curve(clf, 'Learning curve', data, target, cv=cv, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Classifier and cross-validation method\n",
    "clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C, probability=True)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(clf, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Data augmentation is a strategy that increase the diversity of data available for training models, without actually collecting new data. The data augmentation techniques used in this situation are vertical flipping and translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start data augmentation part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T21:14:42.361407Z",
     "start_time": "2019-09-25T21:14:37.894341Z"
    }
   },
   "outputs": [],
   "source": [
    "data_aug, target_aug = data, target\n",
    "data_aug = np.concatenate((data_aug, -data))\n",
    "target_aug = np.concatenate((target_aug, target))\n",
    "\n",
    "for i in range(1,100):\n",
    "    data_aug = np.concatenate((data_aug, np.roll(data, i, axis=1)))\n",
    "    data_aug = np.concatenate((data_aug, -np.roll(data, i, axis=1)))\n",
    "    target_aug = np.concatenate((target_aug, target))\n",
    "    target_aug = np.concatenate((target_aug, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T21:14:42.770194Z",
     "start_time": "2019-09-25T21:14:42.363069Z"
    }
   },
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-25T21:14:39.700Z"
    }
   },
   "outputs": [],
   "source": [
    "maxthreads = 4\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "c = threading.Condition()\n",
    "\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data_aug\n",
    "    global target_aug\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, clf.score(X_test, y_test))\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "\n",
    "    \n",
    "## K-FOLD\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rkf.split(data_aug, target_aug):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# Print final score\n",
    "print('Average score (k-fold):', scores.mean(), '+-', scores.std())\n",
    "\n",
    "\n",
    "## STRATIFIED K-FOLD\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data_aug, target_aug):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# Print final score\n",
    "print('Average score (Stratified k-fold):', scores.mean(), '+-', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-25T21:15:41.381Z"
    }
   },
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier training\n",
    "\n",
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start Bagging Classifier k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "clf = BaggingClassifier(SVC(kernel=best_kernel, gamma=best_gamma, C=best_C), n_estimators=n_estimators, max_samples=1./n_estimators, n_jobs=-1)\n",
    "\n",
    "\n",
    "## K-FOLD\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores_rkf = np.array([])\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rkf.split(data_aug, target_aug):\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores_rkf = np.append(scores_rkf, clf.score(X_test, y_test))\n",
    "# Print final score\n",
    "print('Average score (k-fold):', scores_rkf.mean(), '+-', scores_rkf.std())\n",
    "\n",
    "\n",
    "## STRATIFIED K-FOLD\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores_rskf = np.array([])\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data_aug, target_aug):\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores_rskf = np.append(scores_rskf, clf.score(X_test, y_test))\n",
    "# Print final score\n",
    "print('Average score (Stratified k-fold):', scores_rskf.mean(), '+-', scores_rskf.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End Bagging Classifier k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End data augmentation part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End no multi glitch part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YES MULTI GLITCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start yes multi glitch part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Load data and target from `classification/ris/OUT-classified-merged.h5` and load into numpy arrays.\n",
    "\n",
    "**Label `0` = NO GLITCH**\n",
    "\n",
    "**Label `1` = GLITCH and MULTI GLITCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('../../classification/ris/OUT-classified-merged.h5', mode='r') as in_data:\n",
    "    data = np.concatenate((data, in_data['MULTI_GLITCH'].to_numpy()))\n",
    "    target = np.concatenate((target, np.ones(len(in_data['MULTI_GLITCH'].to_numpy()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best training\n",
    "\n",
    "Initialize best hyper-parameters founded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel = 'rbf'\n",
    "best_gamma = 0.0151\n",
    "best_C = 1.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "Use k-fold to make a cross validation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxthreads = 4\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "c = threading.Condition()\n",
    "\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data\n",
    "    global target\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, clf.score(X_test, y_test))\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "    \n",
    "\n",
    "## K-FOLD\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rkf.split(data, target):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# Print final score\n",
    "print('Average score (k-fold):', scores.mean(), '+-', scores.std())\n",
    "\n",
    "\n",
    "## STRATIFIED K-FOLD\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data, target):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# Print final score\n",
    "print('Average score (Stratified k-fold):', scores.mean(), '+-', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Data augmentation is a strategy that increase the diversity of data available for training models, without actually collecting new data. The data augmentation techniques used in this situation are vertical flipping and translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start data augmentation part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug, target_aug = data, target\n",
    "data_aug = np.concatenate((data_aug, -data))\n",
    "target_aug = np.concatenate((target_aug, target))\n",
    "\n",
    "for i in range(1,100):\n",
    "    data_aug = np.concatenate((data_aug, np.roll(data, i, axis=1)))\n",
    "    data_aug = np.concatenate((data_aug, -np.roll(data, i, axis=1)))\n",
    "    target_aug = np.concatenate((target_aug, target))\n",
    "    target_aug = np.concatenate((target_aug, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxthreads = 4\n",
    "sema = threading.Semaphore(value=maxthreads)\n",
    "c = threading.Condition()\n",
    "\n",
    "def thread_function(train_index, test_index):\n",
    "    # Acquire a semaphore slot\n",
    "    sema.acquire()\n",
    "    # Set global variables\n",
    "    global data_aug\n",
    "    global target_aug\n",
    "    global scores\n",
    "    global best_kernel\n",
    "    global best_gamma\n",
    "    global best_C\n",
    "    # Load training and testing data\n",
    "    c.acquire()\n",
    "    clf = SVC(kernel=best_kernel, gamma=best_gamma, C=best_C)\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Save the score\n",
    "    c.acquire()\n",
    "    scores = np.append(scores, clf.score(X_test, y_test))\n",
    "    c.notify_all()\n",
    "    c.release()\n",
    "    # Release the semaphore slot\n",
    "    sema.release()\n",
    "\n",
    "    \n",
    "## K-FOLD\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rkf.split(data_aug, target_aug):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# Print final score\n",
    "print('Average score (k-fold):', scores.mean(), '+-', scores.std())\n",
    "\n",
    "\n",
    "## STRATIFIED K-FOLD\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores = np.array([])\n",
    "threads = []\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data_aug, target_aug):\n",
    "    thread = threading.Thread(target=thread_function, args=(train_index, test_index))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "# Print final score\n",
    "print('Average score (Stratified k-fold):', scores.mean(), '+-', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier training\n",
    "\n",
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] Start Bagging Classifier k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "clf = BaggingClassifier(SVC(kernel=best_kernel, gamma=best_gamma, C=best_C), n_estimators=n_estimators, max_samples=1./n_estimators, n_jobs=-1)\n",
    "\n",
    "\n",
    "## K-FOLD\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores_rkf = np.array([])\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rkf.split(data_aug, target_aug):\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores_rkf = np.append(scores_rkf, clf.score(X_test, y_test))\n",
    "# Print final score\n",
    "print('Average score (k-fold):', scores_rkf.mean(), '+-', scores_rkf.std())\n",
    "\n",
    "\n",
    "## STRATIFIED K-FOLD\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=None)\n",
    "scores_rskf = np.array([])\n",
    "# Make k-fold CV\n",
    "for train_index, test_index in rskf.split(data_aug, target_aug):\n",
    "    X_train, X_test = data_aug[train_index], data_aug[test_index]\n",
    "    y_train, y_test = target_aug[train_index], target_aug[test_index]\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores_rskf = np.append(scores_rskf, clf.score(X_test, y_test))\n",
    "# Print final score\n",
    "print('Average score (Stratified k-fold):', scores_rskf.mean(), '+-', scores_rskf.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End Bagging Classifier k-fold validation.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End data augmentation part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_id = toml.load('../telegram_bot_id.toml')\n",
    "params = {'chat_id': telegram_bot_id['chat_id'], 'text': '[python] End yes multi glitch part.'}\n",
    "requests.post('https://api.telegram.org/' + telegram_bot_id['bot_id'] + '/sendMessage', params=params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
