{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN DATA\n",
    "\n",
    "Remove the galactic dust, the point sources and the galactic dipole from RAW data; this is necessary to make a correct classification of the glitches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files\n",
    "import healpy as hp\n",
    "from astropy.io import fits\n",
    "import h5py\n",
    "\n",
    "# Scientific computing & plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import time\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model constants and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPERATING_DAY = \"095\"\n",
    "FILENAME_PTG = \"/mnt/d/Tesi/data/HFI-143/HFI_TOI_143-PTG_R2.01_OD0\" + OPERATING_DAY + \".fits\"\n",
    "FILENAME_RAW = \"/mnt/d/Tesi/data/HFI-143/HFI_TOI_143-RAW_R2.00_OD0\" + OPERATING_DAY + \".fits\"\n",
    "FILENAME_SCI = \"/mnt/d/Tesi/data/HFI-143/HFI_TOI_143-SCI_R2.00_OD0\" + OPERATING_DAY + \".fits\"\n",
    "\n",
    "DETECTOR = \"143-5\"\n",
    "\n",
    "DIR = \"ris/ipynb_test-clean_data-moving_average\"#/OD\" + OPERATING_DAY + \"_\" + DETECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open(FILENAME_SCI) as f:\n",
    "    T_CMB = f[DETECTOR].header[\"T_CMB\"]\n",
    "    SOLSYSDIR_ECL_COLAT_RAD = f[DETECTOR].header[\"ECL_THE\"]\n",
    "    SOLSYSDIR_ECL_LONG_RAD = f[DETECTOR].header[\"ECL_PHI\"]\n",
    "    SOLSYSSPEED_M_S = f[DETECTOR].header[\"SOLSPEED\"]\n",
    "    MAIN_LENGTH = len(f[DETECTOR].data.field(\"SIGNAL\"))\n",
    "    CALIBRATION_CONSTANT = f[DETECTOR].header[\"CALIB\"]\n",
    "    ZERO_POINT = f[DETECTOR].header[\"ZERO-PT\"]\n",
    "\n",
    "# Number of elements of the average\n",
    "MA_LENGTH = 649346\n",
    "# New length\n",
    "NEW_LENGTH = MAIN_LENGTH - MA_LENGTH + 1\n",
    "\n",
    "SPEED_OF_LIGHT_M_S = 2.99792458e8\n",
    "PLANCK_H_MKS = 6.62606896e-34\n",
    "BOLTZMANN_K_MKS = 1.3806504e-23\n",
    "\n",
    "SOLSYS_SPEED_VEC_M_S = SOLSYSSPEED_M_S * np.array(\n",
    "                                                  [\n",
    "                                                   np.sin(SOLSYSDIR_ECL_COLAT_RAD) * np.cos(SOLSYSDIR_ECL_LONG_RAD),\n",
    "                                                   np.sin(SOLSYSDIR_ECL_COLAT_RAD) * np.sin(SOLSYSDIR_ECL_LONG_RAD),\n",
    "                                                   np.cos(SOLSYSDIR_ECL_COLAT_RAD),\n",
    "                                                  ]\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning model\n",
    "\n",
    "Since the purpose of this thesis is to detect glitches and not to clean up the RAW signal from the galactic signal and other signals, all points that are on the galactic plane or coincide with a point source can be ignored without any consequences.\n",
    "\n",
    "### Mask\n",
    "\n",
    "Load galactic dust and point sources flags from the SCI data. SCI data, taken as PTG and RAW data from the Planck Legacy Archive (PLA), are the so-called _scientific data_ (already cleaned of various effects and glitches) and each data has a flag that indicates a peculiarity, i.e. point object, planet, galaxy plane and others. In particular, the flags of interest are those concerning the _galactic plane_ and the _point source_:\n",
    "```\n",
    "bit 4: StrongSignal; 1 = In Galactic plane\n",
    "bit 5: StrongSource; 1 = On point source\n",
    "```\n",
    "Data with those flags must be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open SCI data and load the \"FLAG\" field\n",
    "with fits.open(FILENAME_SCI) as f:\n",
    "    SCI_FLAG_bits = f[DETECTOR].data.field(\"FLAG\")\n",
    "    \n",
    "# Unpacks bits\n",
    "SCI_FLAG_bits = np.unpackbits(SCI_FLAG_bits[:, np.newaxis], axis=1)\n",
    "\n",
    "# Read the 4th and 5th bits\n",
    "SCI_FLAG_GD = SCI_FLAG_bits[:,3]\n",
    "SCI_FLAG_PS = SCI_FLAG_bits[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the two masks\n",
    "MASK = SCI_FLAG_GD + SCI_FLAG_PS\n",
    "# Make \"average\"\n",
    "MASK = MASK[:NEW_LENGTH]\n",
    "\n",
    "# Every value above 0 means an unacceptable value\n",
    "MASK[MASK != 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAW data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the voltages\n",
    "with fits.open(FILENAME_RAW) as f:\n",
    "    obt = f[\"OBT\"].data.field(\"OBT\")\n",
    "    data_raw = f[DETECTOR].data.field(\"RAW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA\n",
    "\n",
    "Data calibration allows us to compare data from different detectors: to do this, we use calibration constants extracted from SCI data. The complete equation is:\n",
    "\n",
    "$$\n",
    "S_{\\text{calibrated}} = \\frac{ (S - C_{\\text{zero-point}}) \\cdot C_{\\text{V-to-W}} }{ C_{\\text{calibration}} }  \\qquad \\text{with} \\qquad S = \\frac{ S_{\\text{corrected}} - \\text{movingAverage}(S_{\\text{corrected}}, N_{\\text{one-hour-data}}) }{ N_{\\text{one-hour-data}} }\n",
    "$$\n",
    "\n",
    "where $S_{\\text{corrected}}$ is $S_{\\text{raw}}$, but with the odd components (we start from zero) of the array with a changed sign.\n",
    "\n",
    "We **miss** the $C_{\\text{V-to-W}}$ constant, so we use $C_{\\text{V-to-W}} = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_corrected = np.array(data_raw)\n",
    "data_raw_corrected[1::2] = - data_raw_corrected[1::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the moving average, we use `pandas.Series(x).rolling(window=N).mean()` instead of a numpy method such as `np.convolve(x, np.ones((N,))/N, mode='valid')` because the speed per loop is much greater:\n",
    "```python\n",
    "In [1]: import numpy as np\n",
    "\n",
    "In [2]: import pandas as pd\n",
    "\n",
    "In [3]: x = np.random.random(100000)\n",
    "\n",
    "In [4]: N = 10000\n",
    "\n",
    "In [5]: %timeit np.convolve(x, np.ones((N,))/N, mode='valid')\n",
    "158 ms ± 7.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "In [6]: %timeit pd.Series(x).rolling(window=N).mean().iloc[N-1:].values\n",
    "3.13 ms ± 296 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "```\n",
    "To get a numpy array from the pandas dataframe we use `.iloc[N-1:].values` ; the new number of elements of the array is:\n",
    "```python\n",
    "NEW_LENGTH = len(x) - N + 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average\n",
    "data_ma = pd.Series(data_raw_corrected).rolling(window=MA_LENGTH).mean().iloc[MA_LENGTH-1:].values\n",
    "data = (data_raw_corrected[:NEW_LENGTH] - data_ma) / MA_LENGTH\n",
    "# Calibrate values\n",
    "data = (data - ZERO_POINT) / CALIBRATION_CONSTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now data are in $\\text{T}_{\\text{cmb}} \\text{V} \\text{W}^{-1}$ because we miss $C_{\\text{V-to-W}}$.\n",
    "\n",
    "#### TIME\n",
    "\n",
    "First the OBT (_on board time_) must be converted to seconds using a conversion constant $C_{\\text{time}}$ and removing the offset:\n",
    "\n",
    "$$\n",
    "\\text{time} = \\frac{\\text{OBT} - \\text{OBT}_0}{C_{\\text{time}}} \\qquad \\text{with} \\qquad C_{\\text{time}} = 65536\n",
    "$$\n",
    "\n",
    "Then we take the first `NEW_LENGTH` elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the time from OBT clock to seconds and remove the offset\n",
    "time = (obt - obt[0]) / 65536\n",
    "# Take the correct number of elements\n",
    "time = time[:NEW_LENGTH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GALACTIC DIPOLE\n",
    "\n",
    "`get_dipole_temperature(directions)` : given one or more one-length versors, return the intensity of the CMB dipole; vectors must be expressed in the ecliptic coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dipole_temperature(directions):\n",
    "    \n",
    "    beta = SOLSYS_SPEED_VEC_M_S / SPEED_OF_LIGHT_M_S\n",
    "    gamma = (1 - np.dot(beta, beta)) ** (-0.5)\n",
    "    \n",
    "    return T_CMB * (1.0 / (gamma * (1 - np.dot(directions, beta))) - 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the galactic dipole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open PTG data and load the \"THETA\" and \"PHI\" fields\n",
    "with fits.open(FILENAME_PTG) as inpf:\n",
    "    theta, phi = [inpf[DETECTOR].data.field(x) for x in (\"THETA\", \"PHI\")]\n",
    "    \n",
    "# Get the directions (vectors) directly from the angular coordinates\n",
    "directions = hp.ang2vec(theta, phi)[:NEW_LENGTH]\n",
    "\n",
    "# Compute dipole temperature\n",
    "dipole = get_dipole_temperature(directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here an example of the galactic dipole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time[:10000], dipole[:10000])\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Temperature [K]\")\n",
    "plt.title(\"Dipole temperature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove galactic dipole signal\n",
    "\n",
    "##### **WARNING**: USING SCI DATA, WE HAVE CONVERTED RAW DATA FROM VOLTAGES TO TEMPERATURES, SO _MAYBE_ WE CAN SIMPY SUBTRACT THE GALACTIC DIPOLE FROM THE DATA. IT DEPENDS ON THE CONVERSION CONSTANT WE MISS.\n",
    "\n",
    "Apply a least squares method to remove the galactic dipole. We must use this method because `data` and `dipole` do not have the same units of measurement. Since the RAW data are modulated by the dipole, it's possible to find a correlation of the type $y = m x + q$:\n",
    "\n",
    "$$\n",
    "S_{\\text{calibrated}} = m \\cdot D + q\n",
    "$$\n",
    "\n",
    "where $S_{\\text{calibrated}}$ is the signal after the calibration process (in $\\text{T}_{\\text{cmb}} \\text{V} \\text{W}^{-1}$) and $D$ is the galactic dipole (in $\\text{T}_{\\text{cmb}}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the medians for the data and the dipole temperatures\n",
    "#median_data = sts.median(data)\n",
    "#median_dipole = sts.median(dipole)\n",
    "# Rescale accordingly\n",
    "#data = data - median_data\n",
    "#dipole = dipole - median_dipole\n",
    "\n",
    "# Make the regression\n",
    "sol_m, sol_q = np.linalg.lstsq(dipole[:, np.newaxis] * [1, 0] + [0,1], data, rcond=None)[0]\n",
    "\n",
    "# Print solutions\n",
    "print(\"m:\", sol_m)\n",
    "print(\"q:\", sol_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the correlation we have found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dipole[:10000], data[:10000])\n",
    "x_linreg = np.linspace(-0.0033, 0.003, 10)\n",
    "plt.plot(x_linreg, x_linreg * sol_m + sol_q)\n",
    "plt.ylim(-10, 10)\n",
    "plt.title(\"Correlation between galactic dipole and data\")\n",
    "plt.xlabel(\"Dipole [K]\")\n",
    "plt.ylabel(\"Data [T_cmb V / W]\")\n",
    "plt.legend([\"dipole-data\", \"Linear regression\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the final voltage will be:\n",
    "\n",
    "$$\n",
    "S_{\\text{final}} = S_{\\text{calibrated}} - (m \\cdot D + q)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the dipole out of the data\n",
    "data_final = data - (dipole * sol_m + sol_q)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(time[:5000],data[:5000])\n",
    "plt.plot(time[:5000],data[:5000] - (dipole[:5000]*sol_m + sol_q))\n",
    "plt.ylim(-5,15)\n",
    "#plt.plot(time[:100],data[:100])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(time[:100],data_raw[:100])\n",
    "plt.plot(time[:100],data_raw_corrected[:100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot data before and after the dipole correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time[:15000], data[:15000])\n",
    "plt.plot(time[:15000], data_final[:15000])\n",
    "plt.title(\"Data after and before the dipole correction\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Data [T_cmb V / W]\")\n",
    "plt.legend([\"data before dipole correction\", \"data after dipole correction\"])\n",
    "plt.ylim(-6, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out from the data the directions corresponding to the galactic dust mask\n",
    "data_cleaned = data_final[MASK == 0]\n",
    "holed_raw = data[MASK == 0]\n",
    "# Take out also on the time - this way I can have \"holes\" in the graph\n",
    "time_cleaned = time[MASK == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data\n",
    "\n",
    "We use the Pandas interface to PyTables / HDF5 (speed and compression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR):\n",
    "    print(\"Creating '\" + DIR + \"' directory\")\n",
    "    os.makedirs(DIR)\n",
    "\n",
    "with pd.HDFStore(DIR + \"/OUT-cleaned.h5\") as out_file:\n",
    "    # Save file\n",
    "    out_file.put(OPERATING_DAY + \"/\" + DETECTOR, pd.DataFrame({\"time_cleaned\": time_cleaned, \"data_cleaned\": data_cleaned}, columns=[\"time_cleaned\", \"data_cleaned\"]))\n",
    "    # Write attributes\n",
    "    out_file.get_storer(OPERATING_DAY + \"/\" + DETECTOR).attrs[\"TITLE\"] = np.string_(\"ipynb_test - Data cleaning output file\")\n",
    "    out_file.get_storer(OPERATING_DAY + \"/\" + DETECTOR).attrs[\"VERSION\"] = np.string_(\"Date: \" + time.asctime() + \" | Script: clean_data-moving_average.ipynb | GitHub commit ID: \" + subprocess.run([\"git\", \"log\", \"-1\", \"--format=%H\"], stdout=subprocess.PIPE).stdout.decode(\"ASCII\").rstrip())\n",
    "    out_file.get_storer(OPERATING_DAY + \"/\" + DETECTOR).attrs[\"metadata\"] = np.string_(\"OD/DETECTOR: \" + str(out_file.keys()))\n",
    "    \n",
    "    print(out_file.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read attributes to verify   \n",
    "with h5py.File(DIR + \"/OUT-cleaned.h5\", \"r\") as f:\n",
    "    print(f[OPERATING_DAY + \"/\" + DETECTOR].attrs[\"TITLE\"])\n",
    "    print(f[OPERATING_DAY + \"/\" + DETECTOR].attrs[\"VERSION\"])\n",
    "    print(f[OPERATING_DAY + \"/\" + DETECTOR].attrs[\"metadata\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR + \"/plots\"):\n",
    "    print(\"Creating '\" + DIR + \"/plots' directory\")\n",
    "    os.makedirs(DIR + \"/plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Galactic dipole - first `120s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = time < 120.\n",
    "plt.plot(time[index], dipole[index])\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Temperature [K]\")\n",
    "plt.title(\"Dipole temperature (OD\" + OPERATING_DAY + \"_\" + DETECTOR  + \")\")\n",
    "plt.savefig(DIR + \"/plots/OD\" + OPERATING_DAY + \"_\" + DETECTOR + \"-dipole_example.png\", dpi=600)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = time < 120.\n",
    "plt.plot(dipole[index], data[index])\n",
    "x_linreg = np.linspace(-0.0033, 0.003, 10)\n",
    "plt.plot(x_linreg, x_linreg * sol_m + sol_q)\n",
    "plt.ylim(-10, 10)\n",
    "plt.title(\"Correlation between galactic dipole and data (OD\" + OPERATING_DAY + \"_\" + DETECTOR  + \")\")\n",
    "plt.xlabel(\"Dipole [K]\")\n",
    "plt.ylabel(\"Data [T_cmb V / W]\")\n",
    "plt.legend([\"dipole-data\", \"Linear regression\"])\n",
    "plt.savefig(DIR + \"/plots/OD\" + OPERATING_DAY + \"_\" + DETECTOR + \"-dipole_data_correlation.png\", dpi=600)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between RAW data and cleaned data - first `30s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = time < 30.\n",
    "plt.plot(time[index], data[index], marker='.', linestyle='none', color='#4496e7', alpha=0.9, label=\"with dipole\")\n",
    "plt.plot(time[index], data_final[index], marker='.', linestyle='none', color='#df413a', alpha=0.9, label=\"without dipole\")\n",
    "plt.ylim(-5,20)\n",
    "plt.title(\"Before and after dipole removal signal (without mask) (OD\" + OPERATING_DAY + \"_\" + DETECTOR  + \")\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Signal [V]\")\n",
    "plt.legend([\"Raw data\", \"Cleaned data\"])\n",
    "plt.savefig(DIR + \"/plots/OD\" + OPERATING_DAY + \"_\" + DETECTOR + \"-first30s-data_raw_signal.png\", dpi=600)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "index = time_cleaned < 30.\n",
    "plt.plot(time_cleaned[index], holed_raw[index], marker='.', linestyle='none', color='#4496e7',  alpha=0.9, label=\"with dipole\")\n",
    "plt.plot(time_cleaned[index], data_cleaned[index], marker='.', linestyle='none', color='#df413a', alpha=0.9, label=\"without dipole\")\n",
    "plt.ylim(-5,20)\n",
    "plt.title(\"Before and after dipole removal signal (with mask) (OD\" + OPERATING_DAY + \"_\" + DETECTOR  + \")\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Signal [V]\")\n",
    "plt.legend([\"Raw data\", \"Cleaned data\"])\n",
    "plt.savefig(DIR + \"/plots/OD\" + OPERATING_DAY + \"_\" + DETECTOR + \"-first30s-data_cleaned_signal.png\", dpi=600)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between RAW data and cleaned data - random `30s`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(10):\n",
    "    start = np.random.randint(0,86400)\n",
    "\n",
    "    index1 = time < start + 30\n",
    "    index2 = time > start\n",
    "    index = index1*index2\n",
    "    plt.plot(time[index], data[index], marker='.', linestyle='none', color='#4496e7', alpha=0.9, label=\"with dipole\")\n",
    "    plt.plot(time[index], data_final[index], marker='.', linestyle='none', color='#df413a', alpha=0.9, label=\"without dipole\")\n",
    "    plt.title(\"Before and after dipole removal signal (without mask)\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Signal [V]\")\n",
    "    plt.legend([\"Raw data\", \"Cleaned data\"])\n",
    "    plt.savefig(DIR + \"/plots/\" + str(start) + \"-data_raw_signal.png\", dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "    index1 = time_cleaned < start + 30\n",
    "    index2 = time_cleaned > start\n",
    "    index = index1*index2\n",
    "    plt.plot(time_cleaned[index], holed_raw[index], marker='.', linestyle='none', color='#4496e7', alpha=0.9, label=\"with dipole\")\n",
    "    plt.plot(time_cleaned[index], data_cleaned[index], marker='.', linestyle='none', color='#df413a', alpha=0.9, label=\"without dipole\")\n",
    "    plt.title(\"Before and after dipole removal signal (with mask)\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Signal [V]\")\n",
    "    plt.legend([\"Raw data\", \"Cleaned data\"])\n",
    "    plt.savefig(DIR + \"/plots/\" + str(start) + \"-data_cleaned_signal.png\", dpi=600)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
